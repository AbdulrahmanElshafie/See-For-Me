# Abstract
In this vast world, around 40-45 million people suffer from blindness. With the technologies made to help these people with their issues to help them live their lives as any other person and with the adoption of AI and its massive improvement lately, we decided to take a share in the efforts invested to help these people by using the power and intelligence of AI to help them in their daily life.

# Introduction
The basic idea of the project is to simulate normal human vision and provide an experience close to the natural one. This is an attempt to provide the eye's functionality, which includes seeing the surrounding area and being aware of it, reading, helping while walking, etc. Through this process, we should have an attempt that mimics the human eye to give the blind person a feeling of being able to see, read, and realize. That will be a support and help for him so he can live and do his daily tasks normally without relying much on the help of others.

# Problem Definition
Mimicking human eyes and functions in software functions through AI algorithms and models to provide a blind person with the feel of the natural eye in his daily life.

# Objectives
By the of this project we should have software that helps a blind person in the following:
● Independent from others, can do what he wants whenever he wants.
● Help blind people to have sight-like ability to see and act, navigate, and communicate
with the community, money tasks, and daily tasks independently.
● Replacement for the eye.

# Proposed Solution
We decided that our project should include the following features:
1. **Perception**: The ability to mimic the human perception and understanding of the surrounding area like objects, places, and the surrounding scenes.
2. **Reading**: The ability to read text whether from papers or screens.
3. **Navigation**: The ability to navigate through places, move around the street while avoiding collision, and reach a destination safely and efficiently.

A common function for all of these features is that the result will be spoken loudly so the user can hear what he asks for when using a feature. The system should be implemented in hardware like glasses like Envision due to its ease of use, versatility, and the ability to move around with it freely. However, due to the constrain of time and resources available for the project, we will be implementing the software part only and may test it using a mobile app that will benefit and inspire from the previously made projects.
